{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, Add\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR FFT:\n",
    "width, height = 432, 288\n",
    "train_path = \"spec_imgs2/train\"\n",
    "test_path = \"spec_imgs2/test\"\n",
    "num_train_samples = len(os.listdir(\"spec_imgs2/train/cat\")) + len(os.listdir(\"spec_imgs2/train/dog\"))\n",
    "num_test_samples = len(os.listdir(\"spec_imgs2/test/cat\")) + len(os.listdir(\"spec_imgs2/test/dog\"))\n",
    "\n",
    "# FOR GAF\n",
    "#width, height = 50, 50\n",
    "#train_path = \"output/cat_dog/train\"\n",
    "#test_path = \"output/cat_dog/test\"\n",
    "#arr_train = os.listdir(train_path)\n",
    "#num_train_samples = len(os.listdir(\"output/cat_dog/train/cat\")) + len(os.listdir(\"output/cat_dog/train/dog\"))\n",
    "#num_test_samples = len(os.listdir(\"output/cat_dog/test/cat\")) + len(os.listdir(\"output/cat_dog/test/dog\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation.\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255, \n",
    "        shear_range=0.2, \n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 218 images belonging to 2 classes.\n",
      "Found 55 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set batch size for test generator to a number that divides into your \n",
    "# num_test_samples exactly.\n",
    "# In this case num_test_samples = 67, so we will use 1 \n",
    "batch_size_test = 1\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(width, height),\n",
    "        batch_size=15,\n",
    "        class_mode='binary',\n",
    "        shuffle = False)\n",
    "\n",
    "testing_set = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(width, height),\n",
    "        batch_size=batch_size_test,\n",
    "        class_mode='binary',\n",
    "        shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional network\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, width, height)\n",
    "else:\n",
    "    input_shape = (width, height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st layer\n",
    "model.add(Conv2D(32, (2, 2), strides=(2, 2), input_shape=input_shape))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 2nd layer\n",
    "model.add(Conv2D(32, (2, 2), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 3rd hidden layer\n",
    "model.add(Conv2D(32, (2, 2), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Flatten\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 216, 144, 32)      416       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_5 (Average (None, 108, 72, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 108, 72, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 108, 72, 32)       4128      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_6 (Average (None, 54, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 54, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 54, 36, 32)        4128      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_7 (Average (None, 27, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 27, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 15552)             0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 15552)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                995392    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,004,129\n",
      "Trainable params: 1,004,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 7s 460ms/step - loss: 0.7161 - accuracy: 0.4174 - val_loss: 0.6622 - val_accuracy: 0.6567\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 7s 434ms/step - loss: 0.6909 - accuracy: 0.5183 - val_loss: 0.5733 - val_accuracy: 0.6567\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 6s 408ms/step - loss: 0.6870 - accuracy: 0.5734 - val_loss: 0.7515 - val_accuracy: 0.5970\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 6s 418ms/step - loss: 0.6785 - accuracy: 0.5780 - val_loss: 0.7737 - val_accuracy: 0.4776\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 6s 422ms/step - loss: 0.6721 - accuracy: 0.6009 - val_loss: 0.4760 - val_accuracy: 0.6716\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 6s 429ms/step - loss: 0.6617 - accuracy: 0.5963 - val_loss: 0.3930 - val_accuracy: 0.6866\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 6s 422ms/step - loss: 0.6379 - accuracy: 0.6606 - val_loss: 0.6118 - val_accuracy: 0.7313\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 6s 431ms/step - loss: 0.6279 - accuracy: 0.6606 - val_loss: 0.5971 - val_accuracy: 0.8806\n",
      "Epoch 9/10\n",
      " 9/15 [=================>............] - ETA: 2s - loss: 0.6452 - accuracy: 0.7031"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        training_set,\n",
    "        epochs=10,\n",
    "        validation_data=testing_set,\n",
    "        validation_steps=67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the model is trained, evaluate it\n",
    "# OUTPUT: [LOSS, ACCURACY]\n",
    "\n",
    "# Testing accuracy\n",
    "print(model.evaluate_generator(generator=testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training accuracy\n",
    "print(model.evaluate_generator(generator=training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set.reset()\n",
    "pred = model.predict_generator(testing_set, steps=num_test_samples, verbose=1)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "labels = (training_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "predictions = predictions[:70]\n",
    "filenames=testing_set.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"prediction_results.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
